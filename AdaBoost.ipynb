{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd-nIC_lmLEs",
        "outputId": "84cc6b7a-4495-43f1-8620-15e1d9262e67"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waistline</th>\n",
              "      <th>sight_left</th>\n",
              "      <th>sight_right</th>\n",
              "      <th>hear_left</th>\n",
              "      <th>hear_right</th>\n",
              "      <th>SBP</th>\n",
              "      <th>DBP</th>\n",
              "      <th>...</th>\n",
              "      <th>HDL_chole</th>\n",
              "      <th>LDL_chole</th>\n",
              "      <th>triglyceride</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>urine_protein</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>SGOT_AST</th>\n",
              "      <th>SGOT_ALT</th>\n",
              "      <th>gamma_GTP</th>\n",
              "      <th>SMK_stat_type_cd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "      <td>991346.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>47.614491</td>\n",
              "      <td>162.240625</td>\n",
              "      <td>63.284050</td>\n",
              "      <td>81.233358</td>\n",
              "      <td>0.980834</td>\n",
              "      <td>0.978429</td>\n",
              "      <td>1.031495</td>\n",
              "      <td>1.030476</td>\n",
              "      <td>122.432498</td>\n",
              "      <td>76.052627</td>\n",
              "      <td>...</td>\n",
              "      <td>56.936800</td>\n",
              "      <td>113.037692</td>\n",
              "      <td>132.141751</td>\n",
              "      <td>14.229824</td>\n",
              "      <td>1.094224</td>\n",
              "      <td>0.860467</td>\n",
              "      <td>25.989308</td>\n",
              "      <td>25.755051</td>\n",
              "      <td>37.136347</td>\n",
              "      <td>1.608122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.181339</td>\n",
              "      <td>9.282957</td>\n",
              "      <td>12.514241</td>\n",
              "      <td>11.850323</td>\n",
              "      <td>0.605949</td>\n",
              "      <td>0.604774</td>\n",
              "      <td>0.174650</td>\n",
              "      <td>0.171892</td>\n",
              "      <td>14.543148</td>\n",
              "      <td>9.889365</td>\n",
              "      <td>...</td>\n",
              "      <td>17.238479</td>\n",
              "      <td>35.842812</td>\n",
              "      <td>102.196985</td>\n",
              "      <td>1.584929</td>\n",
              "      <td>0.437724</td>\n",
              "      <td>0.480530</td>\n",
              "      <td>23.493386</td>\n",
              "      <td>26.308599</td>\n",
              "      <td>50.424153</td>\n",
              "      <td>0.818507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>20.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>155.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>74.100000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>13.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>45.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>106.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>87.800000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>15.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>85.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>8110.000000</td>\n",
              "      <td>5119.000000</td>\n",
              "      <td>9490.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>9999.000000</td>\n",
              "      <td>7210.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 age         height         weight      waistline  \\\n",
              "count  991346.000000  991346.000000  991346.000000  991346.000000   \n",
              "mean       47.614491     162.240625      63.284050      81.233358   \n",
              "std        14.181339       9.282957      12.514241      11.850323   \n",
              "min        20.000000     130.000000      25.000000       8.000000   \n",
              "25%        35.000000     155.000000      55.000000      74.100000   \n",
              "50%        45.000000     160.000000      60.000000      81.000000   \n",
              "75%        60.000000     170.000000      70.000000      87.800000   \n",
              "max        85.000000     190.000000     140.000000     999.000000   \n",
              "\n",
              "          sight_left    sight_right      hear_left     hear_right  \\\n",
              "count  991346.000000  991346.000000  991346.000000  991346.000000   \n",
              "mean        0.980834       0.978429       1.031495       1.030476   \n",
              "std         0.605949       0.604774       0.174650       0.171892   \n",
              "min         0.100000       0.100000       1.000000       1.000000   \n",
              "25%         0.700000       0.700000       1.000000       1.000000   \n",
              "50%         1.000000       1.000000       1.000000       1.000000   \n",
              "75%         1.200000       1.200000       1.000000       1.000000   \n",
              "max         9.900000       9.900000       2.000000       2.000000   \n",
              "\n",
              "                 SBP            DBP  ...      HDL_chole      LDL_chole  \\\n",
              "count  991346.000000  991346.000000  ...  991346.000000  991346.000000   \n",
              "mean      122.432498      76.052627  ...      56.936800     113.037692   \n",
              "std        14.543148       9.889365  ...      17.238479      35.842812   \n",
              "min        67.000000      32.000000  ...       1.000000       1.000000   \n",
              "25%       112.000000      70.000000  ...      46.000000      89.000000   \n",
              "50%       120.000000      76.000000  ...      55.000000     111.000000   \n",
              "75%       131.000000      82.000000  ...      66.000000     135.000000   \n",
              "max       273.000000     185.000000  ...    8110.000000    5119.000000   \n",
              "\n",
              "        triglyceride     hemoglobin  urine_protein  serum_creatinine  \\\n",
              "count  991346.000000  991346.000000  991346.000000     991346.000000   \n",
              "mean      132.141751      14.229824       1.094224          0.860467   \n",
              "std       102.196985       1.584929       0.437724          0.480530   \n",
              "min         1.000000       1.000000       1.000000          0.100000   \n",
              "25%        73.000000      13.200000       1.000000          0.700000   \n",
              "50%       106.000000      14.300000       1.000000          0.800000   \n",
              "75%       159.000000      15.400000       1.000000          1.000000   \n",
              "max      9490.000000      25.000000       6.000000         98.000000   \n",
              "\n",
              "            SGOT_AST       SGOT_ALT      gamma_GTP  SMK_stat_type_cd  \n",
              "count  991346.000000  991346.000000  991346.000000     991346.000000  \n",
              "mean       25.989308      25.755051      37.136347          1.608122  \n",
              "std        23.493386      26.308599      50.424153          0.818507  \n",
              "min         1.000000       1.000000       1.000000          1.000000  \n",
              "25%        19.000000      15.000000      16.000000          1.000000  \n",
              "50%        23.000000      20.000000      23.000000          1.000000  \n",
              "75%        28.000000      29.000000      39.000000          2.000000  \n",
              "max      9999.000000    7210.000000     999.000000          3.000000  \n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"data/smoking.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sex                 0\n",
              "age                 0\n",
              "height              0\n",
              "weight              0\n",
              "waistline           0\n",
              "sight_left          0\n",
              "sight_right         0\n",
              "hear_left           0\n",
              "hear_right          0\n",
              "SBP                 0\n",
              "DBP                 0\n",
              "BLDS                0\n",
              "tot_chole           0\n",
              "HDL_chole           0\n",
              "LDL_chole           0\n",
              "triglyceride        0\n",
              "hemoglobin          0\n",
              "urine_protein       0\n",
              "serum_creatinine    0\n",
              "SGOT_AST            0\n",
              "SGOT_ALT            0\n",
              "gamma_GTP           0\n",
              "SMK_stat_type_cd    0\n",
              "DRK_YN              0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Initialize the LabelEncoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encode the 'sex' column: converts categorical values like 'Male', 'Female' into numeric values (e.g., 0, 1)\n",
        "df[\"sex\"] = le.fit_transform(df[\"sex\"])\n",
        "\n",
        "# Encode the 'DRK_YN' column: converts drinking status ('Yes', 'No') into numeric values (e.g., 0, 1)\n",
        "df[\"DRK_YN\"] = le.fit_transform(df[\"DRK_YN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waistline</th>\n",
              "      <th>sight_left</th>\n",
              "      <th>sight_right</th>\n",
              "      <th>hear_left</th>\n",
              "      <th>hear_right</th>\n",
              "      <th>SBP</th>\n",
              "      <th>...</th>\n",
              "      <th>LDL_chole</th>\n",
              "      <th>triglyceride</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>urine_protein</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>SGOT_AST</th>\n",
              "      <th>SGOT_ALT</th>\n",
              "      <th>gamma_GTP</th>\n",
              "      <th>SMK_stat_type_cd</th>\n",
              "      <th>DRK_YN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>126.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>...</td>\n",
              "      <td>148.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>20.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>74.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>47.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>...</td>\n",
              "      <td>104.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>...</td>\n",
              "      <td>117.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991341</th>\n",
              "      <td>1.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>92.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>125.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991342</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>84.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>...</td>\n",
              "      <td>77.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>30.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991344</th>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>73.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>21.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991345</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>90.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>...</td>\n",
              "      <td>153.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>24.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>991346 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sex   age  height  weight  waistline  sight_left  sight_right  \\\n",
              "0       1.0  35.0   170.0    75.0       90.0         1.0          1.0   \n",
              "1       1.0  30.0   180.0    80.0       89.0         0.9          1.2   \n",
              "2       1.0  40.0   165.0    75.0       91.0         1.2          1.5   \n",
              "3       1.0  50.0   175.0    80.0       91.0         1.5          1.2   \n",
              "4       1.0  50.0   165.0    60.0       80.0         1.0          1.2   \n",
              "...     ...   ...     ...     ...        ...         ...          ...   \n",
              "991341  1.0  45.0   175.0    80.0       92.1         1.5          1.5   \n",
              "991342  1.0  35.0   170.0    75.0       86.0         1.0          1.5   \n",
              "991343  0.0  40.0   155.0    50.0       68.0         1.0          0.7   \n",
              "991344  1.0  25.0   175.0    60.0       72.0         1.5          1.0   \n",
              "991345  1.0  50.0   160.0    70.0       90.5         1.0          1.5   \n",
              "\n",
              "        hear_left  hear_right    SBP  ...  LDL_chole  triglyceride  \\\n",
              "0             1.0         1.0  120.0  ...      126.0          92.0   \n",
              "1             1.0         1.0  130.0  ...      148.0         121.0   \n",
              "2             1.0         1.0  120.0  ...       74.0         104.0   \n",
              "3             1.0         1.0  145.0  ...      104.0         106.0   \n",
              "4             1.0         1.0  138.0  ...      117.0         104.0   \n",
              "...           ...         ...    ...  ...        ...           ...   \n",
              "991341        1.0         1.0  114.0  ...      125.0         132.0   \n",
              "991342        1.0         1.0  119.0  ...       84.0          45.0   \n",
              "991343        1.0         1.0  110.0  ...       77.0         157.0   \n",
              "991344        1.0         1.0  119.0  ...       73.0          53.0   \n",
              "991345        1.0         1.0  133.0  ...      153.0         163.0   \n",
              "\n",
              "        hemoglobin  urine_protein  serum_creatinine  SGOT_AST  SGOT_ALT  \\\n",
              "0             17.1            1.0               1.0      21.0      35.0   \n",
              "1             15.8            1.0               0.9      20.0      36.0   \n",
              "2             15.8            1.0               0.9      47.0      32.0   \n",
              "3             17.6            1.0               1.1      29.0      34.0   \n",
              "4             13.8            1.0               0.8      19.0      12.0   \n",
              "...            ...            ...               ...       ...       ...   \n",
              "991341        15.0            1.0               1.0      26.0      36.0   \n",
              "991342        15.8            1.0               1.1      14.0      17.0   \n",
              "991343        14.3            1.0               0.8      30.0      27.0   \n",
              "991344        14.5            1.0               0.8      21.0      14.0   \n",
              "991345        15.8            1.0               0.9      24.0      43.0   \n",
              "\n",
              "        gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
              "0            40.0               1.0     1.0  \n",
              "1            27.0               0.0     0.0  \n",
              "2            68.0               1.0     0.0  \n",
              "3            18.0               1.0     0.0  \n",
              "4            25.0               1.0     0.0  \n",
              "...           ...               ...     ...  \n",
              "991341       27.0               1.0     0.0  \n",
              "991342       15.0               1.0     0.0  \n",
              "991343       17.0               0.0     1.0  \n",
              "991344       17.0               1.0     0.0  \n",
              "991345       36.0               0.0     1.0  \n",
              "\n",
              "[991346 rows x 24 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in df.columns:\n",
        "    df[i] = df[i].astype('float64')\n",
        "\n",
        "# Simplify SMK_stat_type_cd from three classes to two:\n",
        "# 1.0 (current smoker) → 1; 2.0, 3.0 (ex-/non-smoker) → 0 — making it a binary classification task\n",
        "df.loc[df[\"SMK_stat_type_cd\"] == 3.0, \"SMK_stat_type_cd\"] = 0.0\n",
        "df.loc[df[\"SMK_stat_type_cd\"] == 2.0, \"SMK_stat_type_cd\"] = 0.0\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>waistline</th>\n",
              "      <th>sight_left</th>\n",
              "      <th>sight_right</th>\n",
              "      <th>hear_left</th>\n",
              "      <th>hear_right</th>\n",
              "      <th>SBP</th>\n",
              "      <th>...</th>\n",
              "      <th>LDL_chole</th>\n",
              "      <th>triglyceride</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>urine_protein</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>SGOT_AST</th>\n",
              "      <th>SGOT_ALT</th>\n",
              "      <th>gamma_GTP</th>\n",
              "      <th>SMK_stat_type_cd</th>\n",
              "      <th>DRK_YN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9.486833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.224972</td>\n",
              "      <td>9.591663</td>\n",
              "      <td>17.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.582576</td>\n",
              "      <td>5.916080</td>\n",
              "      <td>6.324555</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.433981</td>\n",
              "      <td>0.948683</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.165525</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.948683</td>\n",
              "      <td>4.472136</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9.539392</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.602325</td>\n",
              "      <td>10.198039</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.948683</td>\n",
              "      <td>6.855655</td>\n",
              "      <td>5.656854</td>\n",
              "      <td>8.246211</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.539392</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.198039</td>\n",
              "      <td>10.295630</td>\n",
              "      <td>17.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.048809</td>\n",
              "      <td>5.385165</td>\n",
              "      <td>5.830952</td>\n",
              "      <td>4.242641</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8.944272</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.095445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.816654</td>\n",
              "      <td>10.198039</td>\n",
              "      <td>13.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>4.358899</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991341</th>\n",
              "      <td>1.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9.596874</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11.180340</td>\n",
              "      <td>11.489125</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.099020</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991342</th>\n",
              "      <td>1.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9.273618</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.165151</td>\n",
              "      <td>6.708204</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.048809</td>\n",
              "      <td>3.741657</td>\n",
              "      <td>4.123106</td>\n",
              "      <td>3.872983</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>8.246211</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.836660</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.774964</td>\n",
              "      <td>12.529964</td>\n",
              "      <td>14.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>5.477226</td>\n",
              "      <td>5.196152</td>\n",
              "      <td>4.123106</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991344</th>\n",
              "      <td>1.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8.485281</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.544004</td>\n",
              "      <td>7.280110</td>\n",
              "      <td>14.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.894427</td>\n",
              "      <td>4.582576</td>\n",
              "      <td>3.741657</td>\n",
              "      <td>4.123106</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991345</th>\n",
              "      <td>1.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>9.513149</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.224745</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.369317</td>\n",
              "      <td>12.767145</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.948683</td>\n",
              "      <td>4.898979</td>\n",
              "      <td>6.557439</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>991346 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        sex   age  height  weight  waistline  sight_left  sight_right  \\\n",
              "0       1.0  35.0   170.0    75.0   9.486833    1.000000     1.000000   \n",
              "1       1.0  30.0   180.0    80.0   9.433981    0.948683     1.095445   \n",
              "2       1.0  40.0   165.0    75.0   9.539392    1.095445     1.224745   \n",
              "3       1.0  50.0   175.0    80.0   9.539392    1.224745     1.095445   \n",
              "4       1.0  50.0   165.0    60.0   8.944272    1.000000     1.095445   \n",
              "...     ...   ...     ...     ...        ...         ...          ...   \n",
              "991341  1.0  45.0   175.0    80.0   9.596874    1.224745     1.224745   \n",
              "991342  1.0  35.0   170.0    75.0   9.273618    1.000000     1.224745   \n",
              "991343  0.0  40.0   155.0    50.0   8.246211    1.000000     0.836660   \n",
              "991344  1.0  25.0   175.0    60.0   8.485281    1.224745     1.000000   \n",
              "991345  1.0  50.0   160.0    70.0   9.513149    1.000000     1.224745   \n",
              "\n",
              "        hear_left  hear_right    SBP  ...  LDL_chole  triglyceride  \\\n",
              "0             1.0         1.0  120.0  ...  11.224972      9.591663   \n",
              "1             1.0         1.0  130.0  ...  12.165525     11.000000   \n",
              "2             1.0         1.0  120.0  ...   8.602325     10.198039   \n",
              "3             1.0         1.0  145.0  ...  10.198039     10.295630   \n",
              "4             1.0         1.0  138.0  ...  10.816654     10.198039   \n",
              "...           ...         ...    ...  ...        ...           ...   \n",
              "991341        1.0         1.0  114.0  ...  11.180340     11.489125   \n",
              "991342        1.0         1.0  119.0  ...   9.165151      6.708204   \n",
              "991343        1.0         1.0  110.0  ...   8.774964     12.529964   \n",
              "991344        1.0         1.0  119.0  ...   8.544004      7.280110   \n",
              "991345        1.0         1.0  133.0  ...  12.369317     12.767145   \n",
              "\n",
              "        hemoglobin  urine_protein  serum_creatinine  SGOT_AST  SGOT_ALT  \\\n",
              "0             17.1            1.0          1.000000  4.582576  5.916080   \n",
              "1             15.8            1.0          0.948683  4.472136  6.000000   \n",
              "2             15.8            1.0          0.948683  6.855655  5.656854   \n",
              "3             17.6            1.0          1.048809  5.385165  5.830952   \n",
              "4             13.8            1.0          0.894427  4.358899  3.464102   \n",
              "...            ...            ...               ...       ...       ...   \n",
              "991341        15.0            1.0          1.000000  5.099020  6.000000   \n",
              "991342        15.8            1.0          1.048809  3.741657  4.123106   \n",
              "991343        14.3            1.0          0.894427  5.477226  5.196152   \n",
              "991344        14.5            1.0          0.894427  4.582576  3.741657   \n",
              "991345        15.8            1.0          0.948683  4.898979  6.557439   \n",
              "\n",
              "        gamma_GTP  SMK_stat_type_cd  DRK_YN  \n",
              "0        6.324555               1.0     1.0  \n",
              "1        5.196152               0.0     0.0  \n",
              "2        8.246211               1.0     0.0  \n",
              "3        4.242641               1.0     0.0  \n",
              "4        5.000000               1.0     0.0  \n",
              "...           ...               ...     ...  \n",
              "991341   5.196152               1.0     0.0  \n",
              "991342   3.872983               1.0     0.0  \n",
              "991343   4.123106               0.0     1.0  \n",
              "991344   4.123106               1.0     0.0  \n",
              "991345   6.000000               0.0     1.0  \n",
              "\n",
              "[991346 rows x 24 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List of numerical health-related features to transform\n",
        "columns_tranformed = ['waistline','sight_left','sight_right','hear_left','hear_right','BLDS',\n",
        "                      'tot_chole','HDL_chole','LDL_chole','triglyceride','urine_protein',\n",
        "                      'serum_creatinine','SGOT_AST','SGOT_ALT','gamma_GTP']\n",
        "\n",
        "# Apply square root transformation to each selected column to reduce skewness and normalize distribution\n",
        "for i in columns_tranformed:\n",
        "    df[i] = np.sqrt(df[i])\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = df.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr['SMK_stat_type_cd']\n",
        "columns_to_be_scaled = ['age','height','weight','waistline','sight_left','sight_right','hear_left','hear_right',\n",
        "                        'SBP','DBP','BLDS','tot_chole','HDL_chole','LDL_chole','triglyceride','hemoglobin','urine_protein',\n",
        "                        'serum_creatinine','SGOT_AST','SGOT_ALT','gamma_GTP']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler to normalize features (zero mean, unit variance)\n",
        "StandardScaler_object = StandardScaler()\n",
        "\n",
        "# Apply standard scaling to the selected columns to bring all features to the same scale\n",
        "df[columns_to_be_scaled] = StandardScaler_object.fit_transform(df[columns_to_be_scaled])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0.0: 388905, 1.0: 388905})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "# Split features and target variable\n",
        "X = df.drop(\"SMK_stat_type_cd\", axis=1)  # Features (independent variables)\n",
        "y = df[\"SMK_stat_type_cd\"]               # Target (smoker or non-smoker)\n",
        "\n",
        "# Initialize undersampler to balance the dataset by reducing the majority class\n",
        "undersampler = RandomUnderSampler(sampling_strategy=1)\n",
        "X, y = undersampler.fit_resample(X, y)\n",
        "\n",
        "Counter(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(777810, 10)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Apply PCA to reduce dimensionality to 3 principal components\n",
        "pca = PCA(n_components=3)\n",
        "X = pca.fit_transform(X)\n",
        "\n",
        "# Generate polynomial features up to degree 2 (includes interactions and squared terms)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X = poly.fit_transform(X)\n",
        "\n",
        "# Show the new shape of feature matrix after polynomial transformation\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adaboost Implemented from scratch\n",
            "Scratch T-statistic with ground truth: -1.4493439370101584\n",
            "Scratch P-value with ground truth: 0.14731295267096658\n",
            "Accuracy: 0.738\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.76      0.75      1117\n",
            "         1.0       0.74      0.71      0.73      1080\n",
            "\n",
            "    accuracy                           0.74      2197\n",
            "   macro avg       0.74      0.74      0.74      2197\n",
            "weighted avg       0.74      0.74      0.74      2197\n",
            "\n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.78      0.75      4375\n",
            "         1.0       0.76      0.72      0.74      4412\n",
            "\n",
            "    accuracy                           0.75      8787\n",
            "   macro avg       0.75      0.75      0.75      8787\n",
            "weighted avg       0.75      0.75      0.75      8787\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define a simple Decision Stump class used as the weak learner in AdaBoost\n",
        "class Stump:\n",
        "    def __init__(self):\n",
        "        self.polarity = 1          # Direction of inequality\n",
        "        self.threshold = None      # Threshold value for splitting\n",
        "        self.feature_idx = None    # Index of feature used for splitting\n",
        "        self.alpha = None          # Weight of this stump in the final prediction\n",
        "\n",
        "    def predict(self, X):\n",
        "        n_samples = X.shape[0]\n",
        "        X_c = X[:, self.feature_idx]  # Get feature column\n",
        "        preds = np.ones(n_samples)   # Initialize all predictions to 1\n",
        "\n",
        "        # Apply threshold based on polarity\n",
        "        if self.polarity == 1:\n",
        "            preds[X_c < self.threshold] = -1\n",
        "        else:\n",
        "            preds[X_c > self.threshold] = -1\n",
        "\n",
        "        return preds\n",
        "\n",
        "# Define AdaBoost class using decision stumps\n",
        "class adaBoost:\n",
        "    def __init__(self, n_ab=5):   # n_ab: number of weak learners (stumps)\n",
        "        self.n_ab = n_ab\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        w = np.full(n_samples, (1 / n_samples))  # Initialize uniform sample weights\n",
        "\n",
        "        self.abs = []  # List to store trained stumps\n",
        "        for _ in range(self.n_ab):\n",
        "            ab = Stump()\n",
        "            min_error = float('inf')\n",
        "\n",
        "            # Try every feature and threshold to find best stump\n",
        "            for feat in range(n_features):\n",
        "                X_c = X[:, feat]\n",
        "                thresholds = np.unique(X_c)\n",
        "\n",
        "                for threshold in thresholds:\n",
        "                    p = 1\n",
        "                    preds = np.ones(n_samples)\n",
        "                    preds[X_c < threshold] = -1\n",
        "\n",
        "                    # Compute error based on current weights\n",
        "                    misclassified = w[y != preds]\n",
        "                    error = sum(misclassified)\n",
        "\n",
        "                    # Flip polarity if error > 0.5\n",
        "                    if error > 0.5:\n",
        "                        p = -1\n",
        "                        error = 1 - error\n",
        "\n",
        "                    # Save best stump so far\n",
        "                    if error < min_error:\n",
        "                        min_error = error\n",
        "                        ab.threshold = threshold\n",
        "                        ab.feature_idx = feat\n",
        "                        ab.polarity = p\n",
        "\n",
        "            EPS = 1e-10  # Small value to avoid division by zero\n",
        "            ab.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS))  # Compute alpha\n",
        "\n",
        "            preds = ab.predict(X)\n",
        "            # Update weights: increase weights for misclassified points\n",
        "            w *= np.exp(-ab.alpha * y * preds)\n",
        "            w /= np.sum(w)  # Normalize weights\n",
        "\n",
        "            self.abs.append(ab)  # Store the trained stump\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Weighted sum of weak learner predictions\n",
        "        ab_preds = [ab.alpha * ab.predict(X) for ab in self.abs]\n",
        "        y_pred = np.sum(ab_preds, axis=0)\n",
        "        return np.sign(y_pred)  # Final prediction by sign\n",
        "\n",
        "# Convert label 0 to -1 for AdaBoost compatibility (expected labels: -1, 1)\n",
        "y[y == 0] = -1\n",
        "\n",
        "# Split the dataset into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "print(\"Adaboost Implemented from scratch\")\n",
        "\n",
        "# Train AdaBoost on training data\n",
        "ab = adaBoost()\n",
        "ab.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = ab.predict(X_test)\n",
        "ada_y_pred_train = ab.predict(X_train)\n",
        "ada_y_pred_test = ab.predict(X_test)\n",
        "\n",
        "# Evaluate on test data\n",
        "ada_accuracy = accuracy_score(y_test, ada_y_pred_test)\n",
        "ada_classification_rep = classification_report(y_test, ada_y_pred_test)\n",
        "\n",
        "# Perform statistical test to compare predicted vs actual values\n",
        "t_statistic, p_value = ttest_ind(ada_y_pred_test, y_test)\n",
        "print(\"Scratch T-statistic with ground truth:\", t_statistic)\n",
        "print(\"Scratch P-value with ground truth:\", p_value)\n",
        "\n",
        "print(f\"Accuracy: {ada_accuracy:.3f}\")\n",
        "print(\"Classification Report:\\n\", ada_classification_rep)\n",
        "\n",
        "# Evaluate on train data\n",
        "ada_accuracy_t = accuracy_score(y_train, ada_y_pred_train)\n",
        "ada_classification_rep_t = classification_report(y_train, ada_y_pred_train)\n",
        "\n",
        "print(f\"Accuracy: {ada_accuracy_t:.3f}\")\n",
        "print(\"Classification Report:\\n\", ada_classification_rep_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okYftA91SlFc",
        "outputId": "5b2f3b80-fe4e-4169-ccb6-13c881f42152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adaboost Implemented from sklearn\n",
            "Scratch T-statistic with ground truth: -2.206020171953178\n",
            "Scratch P-value with ground truth: 0.027434177023827798\n",
            "Accuracy: 0.764\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.80      0.78      1117\n",
            "         1.0       0.78      0.73      0.75      1080\n",
            "\n",
            "    accuracy                           0.76      2197\n",
            "   macro avg       0.76      0.76      0.76      2197\n",
            "weighted avg       0.76      0.76      0.76      2197\n",
            "\n",
            "Accuracy: 0.773\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.81      0.78      4375\n",
            "         1.0       0.80      0.73      0.76      4412\n",
            "\n",
            "    accuracy                           0.77      8787\n",
            "   macro avg       0.77      0.77      0.77      8787\n",
            "weighted avg       0.77      0.77      0.77      8787\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"Adaboost Implemented from sklearn\")\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier()\n",
        "\n",
        "# Define the parameter grid, including n_estimators, learning_rate, and base_estimator\n",
        "base_classifiers = [DecisionTreeClassifier(max_depth=1)]\n",
        "ada_param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'learning_rate': [0.1],\n",
        "    'base_estimator': base_classifiers\n",
        "}\n",
        "\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "ada_y_pred_train2 = adaboost_classifier.predict(X_train)\n",
        "ada_y_pred_test2 = adaboost_classifier.predict(X_test)\n",
        "\n",
        "ada_accuracy2 = accuracy_score(y_test, ada_y_pred_test2)\n",
        "ada_classification_rep2 = classification_report(y_test, ada_y_pred_test2)\n",
        "\n",
        "t_statistic, p_value = ttest_ind(ada_y_pred_test2, y_test)\n",
        "print(\"Scratch T-statistic with ground truth:\", t_statistic)\n",
        "print(\"Scratch P-value with ground truth:\", p_value)\n",
        "\n",
        "print(f\"Accuracy: {ada_accuracy2:.3f}\")\n",
        "print(\"Classification Report:\\n\", ada_classification_rep2)\n",
        "\n",
        "ada_accuracy_t2 = accuracy_score(y_train, ada_y_pred_train2)\n",
        "ada_classification_rep_t2 = classification_report(y_train, ada_y_pred_train2)\n",
        "\n",
        "print(f\"Accuracy: {ada_accuracy_t2:.3f}\")\n",
        "print(\"Classification Report:\\n\", ada_classification_rep_t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "cq8gymBhhJIA"
      },
      "outputs": [],
      "source": [
        "num_folds = 5\n",
        "fold_size = len(X_train) // num_folds\n",
        "\n",
        "X_train_cv = X_train_cv2 = X_train\n",
        "y_train_cv = y_train_cv2 = y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33jyfnR0Spz1",
        "outputId": "17e82f25-4167-4d28-b0a9-b3c8317bfebd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kfold for Adaboost Implemented from scratch \n",
            "Testing Accuracy: \n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      0.81      0.76      1117\n",
            "         1.0       0.78      0.68      0.72      1080\n",
            "\n",
            "    accuracy                           0.75      2197\n",
            "   macro avg       0.75      0.74      0.74      2197\n",
            "weighted avg       0.75      0.75      0.74      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.71      0.82      0.76      3493\n",
            "         1.0       0.79      0.67      0.73      3537\n",
            "\n",
            "    accuracy                           0.75      7030\n",
            "   macro avg       0.75      0.75      0.74      7030\n",
            "weighted avg       0.75      0.75      0.74      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.745\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.71      0.82      0.76       882\n",
            "         1.0       0.79      0.67      0.72       875\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.75      0.74      0.74      1757\n",
            "weighted avg       0.75      0.75      0.74      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      0.81      0.76      1117\n",
            "         1.0       0.78      0.68      0.72      1080\n",
            "\n",
            "    accuracy                           0.75      2197\n",
            "   macro avg       0.75      0.74      0.74      2197\n",
            "weighted avg       0.75      0.75      0.74      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.744\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.71      0.82      0.76      3465\n",
            "         1.0       0.79      0.67      0.73      3565\n",
            "\n",
            "    accuracy                           0.74      7030\n",
            "   macro avg       0.75      0.75      0.74      7030\n",
            "weighted avg       0.75      0.74      0.74      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.752\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.82      0.77       910\n",
            "         1.0       0.78      0.67      0.72       847\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.76      0.75      0.75      1757\n",
            "weighted avg       0.76      0.75      0.75      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.743\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      0.80      0.76      1117\n",
            "         1.0       0.77      0.68      0.72      1080\n",
            "\n",
            "    accuracy                           0.74      2197\n",
            "   macro avg       0.75      0.74      0.74      2197\n",
            "weighted avg       0.75      0.74      0.74      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      0.81      0.76      3510\n",
            "         1.0       0.78      0.68      0.73      3520\n",
            "\n",
            "    accuracy                           0.75      7030\n",
            "   macro avg       0.75      0.75      0.75      7030\n",
            "weighted avg       0.75      0.75      0.75      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.742\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.70      0.82      0.76       865\n",
            "         1.0       0.79      0.67      0.72       892\n",
            "\n",
            "    accuracy                           0.74      1757\n",
            "   macro avg       0.75      0.74      0.74      1757\n",
            "weighted avg       0.75      0.74      0.74      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.738\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.77      0.75      1117\n",
            "         1.0       0.75      0.71      0.73      1080\n",
            "\n",
            "    accuracy                           0.74      2197\n",
            "   macro avg       0.74      0.74      0.74      2197\n",
            "weighted avg       0.74      0.74      0.74      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.752\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.74      0.79      0.76      3549\n",
            "         1.0       0.77      0.72      0.74      3481\n",
            "\n",
            "    accuracy                           0.75      7030\n",
            "   macro avg       0.75      0.75      0.75      7030\n",
            "weighted avg       0.75      0.75      0.75      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.721\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.69      0.75      0.72       826\n",
            "         1.0       0.76      0.69      0.72       931\n",
            "\n",
            "    accuracy                           0.72      1757\n",
            "   macro avg       0.72      0.72      0.72      1757\n",
            "weighted avg       0.72      0.72      0.72      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.738\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.76      0.75      1117\n",
            "         1.0       0.74      0.71      0.73      1080\n",
            "\n",
            "    accuracy                           0.74      2197\n",
            "   macro avg       0.74      0.74      0.74      2197\n",
            "weighted avg       0.74      0.74      0.74      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.743\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.72      0.78      0.75      3484\n",
            "         1.0       0.77      0.71      0.74      3546\n",
            "\n",
            "    accuracy                           0.74      7030\n",
            "   macro avg       0.74      0.74      0.74      7030\n",
            "weighted avg       0.74      0.74      0.74      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.754\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.76      0.76      0.76       891\n",
            "         1.0       0.75      0.75      0.75       866\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.75      0.75      0.75      1757\n",
            "weighted avg       0.75      0.75      0.75      1757\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# #Kfold\n",
        "\n",
        "print(\"Kfold for Adaboost Implemented from scratch \")\n",
        "for fold in range(num_folds):\n",
        "    # Define the start and end index for the validation set\n",
        "    start_val_index = fold * fold_size\n",
        "    end_val_index = (fold + 1) * fold_size\n",
        "\n",
        "    # New training set\n",
        "    X_train = np.append(X_train_cv[:start_val_index], X_train_cv[end_val_index:], axis=0)\n",
        "    y_train = np.append(y_train_cv[:start_val_index], y_train_cv[end_val_index:])\n",
        "\n",
        "    X_val = X_train_cv[start_val_index:end_val_index]\n",
        "    y_val = y_train_cv[start_val_index:end_val_index]\n",
        "\n",
        "    ## Fitting the model on train data\n",
        "    ab = adaBoost()\n",
        "    ab.fit(X_train, y_train)\n",
        "\n",
        "    predictions = ab.predict(X_test)\n",
        "    ada_y_pred_train = ab.predict(X_train)\n",
        "    ada_y_pred_test = ab.predict(X_test)\n",
        "    ada_y_pred_val = ab.predict(X_val)\n",
        "\n",
        "    ada_accuracy = accuracy_score(y_test, ada_y_pred_test)\n",
        "    ada_classification_rep = classification_report(y_test, ada_y_pred_test)\n",
        "    print(\"Testing Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep)\n",
        "\n",
        "    ada_accuracy_t = accuracy_score(y_train, ada_y_pred_train)\n",
        "    ada_classification_rep_t = classification_report(y_train, ada_y_pred_train)\n",
        "    print(\"Training Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy_t:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep_t)\n",
        "\n",
        "    ada_accuracy_v = accuracy_score(y_val, ada_y_pred_val)\n",
        "    ada_classification_rep_v = classification_report(y_val, ada_y_pred_val)\n",
        "    print(\"Validation Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy_v:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep_v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSe7fRq6ha9i",
        "outputId": "434343b5-f930-4f9f-9f72-8845bab3009d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kfold for Adaboost Implemented using sklearn\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.761\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.74      0.81      0.78      1117\n",
            "         1.0       0.79      0.71      0.74      1080\n",
            "\n",
            "    accuracy                           0.76      2197\n",
            "   macro avg       0.76      0.76      0.76      2197\n",
            "weighted avg       0.76      0.76      0.76      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.777\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.83      0.79      3493\n",
            "         1.0       0.81      0.72      0.77      3537\n",
            "\n",
            "    accuracy                           0.78      7030\n",
            "   macro avg       0.78      0.78      0.78      7030\n",
            "weighted avg       0.78      0.78      0.78      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.746\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.78      0.76       882\n",
            "         1.0       0.76      0.71      0.73       875\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.75      0.75      0.75      1757\n",
            "weighted avg       0.75      0.75      0.75      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.764\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.81      0.78      1117\n",
            "         1.0       0.78      0.72      0.75      1080\n",
            "\n",
            "    accuracy                           0.76      2197\n",
            "   macro avg       0.77      0.76      0.76      2197\n",
            "weighted avg       0.77      0.76      0.76      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.772\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.74      0.82      0.78      3465\n",
            "         1.0       0.80      0.73      0.76      3565\n",
            "\n",
            "    accuracy                           0.77      7030\n",
            "   macro avg       0.77      0.77      0.77      7030\n",
            "weighted avg       0.77      0.77      0.77      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.755\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.79      0.77       910\n",
            "         1.0       0.76      0.72      0.74       847\n",
            "\n",
            "    accuracy                           0.76      1757\n",
            "   macro avg       0.76      0.75      0.75      1757\n",
            "weighted avg       0.76      0.76      0.75      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.766\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.81      0.78      1117\n",
            "         1.0       0.79      0.72      0.75      1080\n",
            "\n",
            "    accuracy                           0.77      2197\n",
            "   macro avg       0.77      0.77      0.77      2197\n",
            "weighted avg       0.77      0.77      0.77      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.772\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.82      0.78      3510\n",
            "         1.0       0.80      0.73      0.76      3520\n",
            "\n",
            "    accuracy                           0.77      7030\n",
            "   macro avg       0.77      0.77      0.77      7030\n",
            "weighted avg       0.77      0.77      0.77      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.752\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.73      0.79      0.76       865\n",
            "         1.0       0.78      0.71      0.74       892\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.75      0.75      0.75      1757\n",
            "weighted avg       0.75      0.75      0.75      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.760\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.74      0.81      0.77      1117\n",
            "         1.0       0.78      0.71      0.74      1080\n",
            "\n",
            "    accuracy                           0.76      2197\n",
            "   macro avg       0.76      0.76      0.76      2197\n",
            "weighted avg       0.76      0.76      0.76      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.780\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.76      0.83      0.79      3549\n",
            "         1.0       0.81      0.73      0.77      3481\n",
            "\n",
            "    accuracy                           0.78      7030\n",
            "   macro avg       0.78      0.78      0.78      7030\n",
            "weighted avg       0.78      0.78      0.78      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.722\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.69      0.75      0.72       826\n",
            "         1.0       0.76      0.70      0.73       931\n",
            "\n",
            "    accuracy                           0.72      1757\n",
            "   macro avg       0.72      0.72      0.72      1757\n",
            "weighted avg       0.72      0.72      0.72      1757\n",
            "\n",
            "Testing Accuracy: \n",
            "Accuracy: 0.765\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.75      0.81      0.78      1117\n",
            "         1.0       0.78      0.72      0.75      1080\n",
            "\n",
            "    accuracy                           0.77      2197\n",
            "   macro avg       0.77      0.76      0.76      2197\n",
            "weighted avg       0.77      0.77      0.76      2197\n",
            "\n",
            "Training Accuracy: \n",
            "Accuracy: 0.771\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.74      0.82      0.78      3484\n",
            "         1.0       0.80      0.72      0.76      3546\n",
            "\n",
            "    accuracy                           0.77      7030\n",
            "   macro avg       0.77      0.77      0.77      7030\n",
            "weighted avg       0.77      0.77      0.77      7030\n",
            "\n",
            "Validation Accuracy: \n",
            "Accuracy: 0.754\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.76      0.76      0.76       891\n",
            "         1.0       0.75      0.75      0.75       866\n",
            "\n",
            "    accuracy                           0.75      1757\n",
            "   macro avg       0.75      0.75      0.75      1757\n",
            "weighted avg       0.75      0.75      0.75      1757\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# #Kfold\n",
        "\n",
        "print(\"Kfold for Adaboost Implemented using sklearn\")\n",
        "for fold in range(num_folds):\n",
        "    # Define the start and end index for the validation set\n",
        "    start_val_index = fold * fold_size\n",
        "    end_val_index = (fold + 1) * fold_size\n",
        "\n",
        "    # New training set\n",
        "    X_train = np.append(X_train_cv2[:start_val_index], X_train_cv2[end_val_index:], axis=0)\n",
        "    y_train = np.append(y_train_cv2[:start_val_index], y_train_cv2[end_val_index:])\n",
        "\n",
        "    X_val = X_train_cv2[start_val_index:end_val_index]\n",
        "    y_val = y_train_cv2[start_val_index:end_val_index]\n",
        "\n",
        "    ## Fitting the model on train data\n",
        "    adaboost_classifier = AdaBoostClassifier()\n",
        "    adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "    predictions = adaboost_classifier.predict(X_test)\n",
        "    ada_y_pred_train = adaboost_classifier.predict(X_train)\n",
        "    ada_y_pred_test = adaboost_classifier.predict(X_test)\n",
        "    ada_y_pred_val = ab.predict(X_val)\n",
        "\n",
        "    ada_accuracy = accuracy_score(y_test, ada_y_pred_test)\n",
        "    ada_classification_rep = classification_report(y_test, ada_y_pred_test)\n",
        "    print(\"Testing Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep)\n",
        "\n",
        "    ada_accuracy_t = accuracy_score(y_train, ada_y_pred_train)\n",
        "    ada_classification_rep_t = classification_report(y_train, ada_y_pred_train)\n",
        "    print(\"Training Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy_t:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep_t)\n",
        "\n",
        "    ada_accuracy_v = accuracy_score(y_val, ada_y_pred_val)\n",
        "    ada_classification_rep_v = classification_report(y_val, ada_y_pred_val)\n",
        "    print(\"Validation Accuracy: \")\n",
        "    print(f\"Accuracy: {ada_accuracy_v:.3f}\")\n",
        "    print(\"Classification Report:\\n\", ada_classification_rep_v)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
